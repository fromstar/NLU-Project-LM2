{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fromstar/NLU-Project-LM2/blob/main/223727_NLU_LM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykBlgtbm_VB_"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hOI4pbnk_KGq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.optim import optimizer\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWofU_Q_A4N2",
        "outputId": "5d69f13f-4270-4642-ac9e-18f77372a857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#Main path to dataset:\n",
        "\n",
        "drive.mount('/content/drive/', force_remount = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-g3IesJCBVs1"
      },
      "outputs": [],
      "source": [
        "!cp -R \"/content/drive/MyDrive/input/\"  \"/content/input\" "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Global Variables"
      ],
      "metadata": {
        "id": "L6PRXv19wl1g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uqQqYUeLEKvb"
      },
      "outputs": [],
      "source": [
        "data = \"/content/input\"\n",
        "device = 'cuda:0'\n",
        "\n",
        "embedding_size = 650\n",
        "hidden_size =650\n",
        "nlayers = 1\n",
        "learning_rate = 0.001\n",
        "clip = 0.35\n",
        "epochs = 25\n",
        "batch_size = 64\n",
        "eval_batch_size = 1\n",
        "dropout = 0.5\n",
        "interval = 50\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocCg3Sm2OW_E"
      },
      "source": [
        "Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iHqZXvVtB_aH"
      },
      "outputs": [],
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self):\n",
        "        self.dictionary = {0: '<pad>', 1: '<unk>', 2: '<bos>', 3: '<eos>'}\n",
        "        self.len_dict = len(self.dictionary)\n",
        "        self.train = self.to_token(os.path.join(data, 'ptb.train.txt'))\n",
        "        self.test = self.to_token(os.path.join(data, 'ptb.test.txt'))\n",
        "        self.valid = self.to_token(os.path.join(data, 'ptb.valid.txt'))\n",
        "\n",
        "# Fill the dictionary and return an array with the corresponding key of the words read\n",
        "    def to_token(self, path):\n",
        "        if os.path.exists(path):  # check if the file I need to read exists\n",
        "            with open(path) as txt:\n",
        "                key = self.len_dict\n",
        "                sentences = []\n",
        "                values = list(self.dictionary.values())\n",
        "\n",
        "                for line in txt:\n",
        "                    tmp = []\n",
        "                    # line = line.strip()\n",
        "                    words = ['<bos>'] + line.split() + ['<eos>']\n",
        "\n",
        "                    # scroll through the words of a sentence\n",
        "                    for word in words:\n",
        "                        # if the world is not in the dictionary I add it.\n",
        "                        if word not in values:\n",
        "                            # the length of the dictionary coincides with the index of insertion in it\n",
        "                            self.dictionary[key] = word\n",
        "                            tmp.append(key)\n",
        "                            key += 1\n",
        "                            values.append(word)\n",
        "                        else:\n",
        "                            tmp.append(values.index(word))\n",
        "                    sentences.append(torch.LongTensor(tmp).to(device))\n",
        "\n",
        "            print(\"Sentences loaded\")\n",
        "            self.len_dict = len(self.dictionary)\n",
        "            return sentences\n",
        "        else:\n",
        "            raise ValueError(path +\" doesn't exist.\")\n",
        "\n",
        "    def print_dic(self):\n",
        "        print(self.dictionary)\n",
        "        print(\"Number of tokens: \" + str(len(self.dictionary)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU"
      ],
      "metadata": {
        "id": "iJYOcU8f2KC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "53kUcinzOssO"
      },
      "outputs": [],
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.update_gate = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.reset_gate = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out_gate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.x = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, prev_state):\n",
        "\n",
        "        seq_size, _, _ = input.size()\n",
        "        hidden_seq = []\n",
        "\n",
        "        for t in range(seq_size):\n",
        "\n",
        "            x_t = input[t, :, :]\n",
        "            x_h = torch.cat((x_t, prev_state), dim=1)\n",
        "\n",
        "            reset = torch.sigmoid(self.reset_gate(x_h))\n",
        "            update = torch.sigmoid(self.update_gate(x_h))\n",
        "\n",
        "            n1 = self.out_gate(prev_state) * reset\n",
        "            n2 = n1 + self.x(x_t)\n",
        "            out = torch.tanh(n2)\n",
        "\n",
        "            new_state = (1 - update) * out + update * prev_state\n",
        "            hidden_seq.append(new_state.unsqueeze(0))\n",
        "\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "\n",
        "        return hidden_seq, new_state"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "M_QZK2ZT2MWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BR_NLg3_Ov7D"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, ntoken):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.ntoken = ntoken\n",
        "        self.nlayers = nlayers\n",
        "        self.input_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        self.encoder = nn.Embedding(ntoken, self.input_size, padding_idx=0)\n",
        "\n",
        "        self.rnn = nn.ModuleList()\n",
        "        # N GRU layers\n",
        "        for i in range(nlayers):\n",
        "            self.rnn.append(GRUCell(self.input_size, hidden_size))\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
        "        self.decoder = nn.Linear(hidden_size, ntoken)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.05\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.drop(self.encoder(input))\n",
        "\n",
        "        for i in range(len(self.rnn)):\n",
        "            output, hidden[i] = self.rnn[i](output, hidden[i])\n",
        "            output = self.drop(output)\n",
        "\n",
        "        output = self.fc(output)\n",
        "        decoded = self.decoder(output)\n",
        "        decoded = decoded.view(-1,self.ntoken)\n",
        "\n",
        "        return F.log_softmax(decoded, dim=1), hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        hidden = []\n",
        "        weight = next(self.parameters())\n",
        "        for i in range(nlayers):\n",
        "            hidden.append(weight.new_zeros(batch_size, self.hidden_size))\n",
        "        return hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng3_VxmVIk_U"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n-YU1ZW5tkYP"
      },
      "outputs": [],
      "source": [
        "def get_batch(source, i, batch_size):\n",
        "    data = []\n",
        "    target = []\n",
        "    size = 0\n",
        "    for sentence in source[batch_size * i: batch_size * (i+1)]:\n",
        "        data.append(sentence[:-1])\n",
        "        target.append(sentence[1:])\n",
        "        size += len(sentence[:-1])\n",
        "\n",
        "    # Fill the sentences with the pad tag in order to make them the same length\n",
        "    # The key for the pad tag is 0.\n",
        "    data = pad_sequence(data, padding_value=0)\n",
        "    target = pad_sequence(target, padding_value=0)\n",
        "\n",
        "    return data, target, size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0WxCA7dVtkKy"
      },
      "outputs": [],
      "source": [
        "def train(model, train, opt, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    total_size = 0\n",
        "\n",
        "    for batch_idx in range(0, len(train) // batch_size):\n",
        "        data, target, size = get_batch(train, batch_idx, batch_size)\n",
        "        output, hidden = model(data, hidden)\n",
        "        # Dropout to recurrent element\n",
        "        # output = nn.Dropout(dropout)(output)\n",
        "\n",
        "        loss = F.nll_loss(\n",
        "                output,\n",
        "                target.view(-1),\n",
        "                reduction='sum',\n",
        "                ignore_index=0,\n",
        "            )\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        total_size += size\n",
        "        if batch_idx % interval == 0 and batch_idx > 0:\n",
        "            cur_loss = total_loss / total_size\n",
        "            ppl = round(math.exp(cur_loss),2)\n",
        "            elapsed = time.time() - start_time\n",
        "            print('epoch: ', epoch, ' | batches: ', batch_idx+1, '/', (len(train) // batch_size), ' | learning_rate: ', learning_rate,\n",
        "                  '| ms/batch: ',round(elapsed * 1000 / interval,2), ' | loss: ', round(cur_loss,3), ' | perplexity: ', ppl)\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "            total_size = 0\n",
        "        \n",
        "        for i in range(len(hidden)):\n",
        "            hidden[i] = hidden[i].detach()\n",
        "\n",
        "def evaluate(data_source, model):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_size = 0\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(data_source)//eval_batch_size):\n",
        "            hidden = model.init_hidden(eval_batch_size)\n",
        "            data, target, size = get_batch(data_source, i, eval_batch_size)\n",
        "            output, hidden = model(data, hidden)\n",
        "            for i in range(len(hidden)):\n",
        "             hidden[i] = hidden[i].detach()\n",
        "             \n",
        "            total_loss += F.nll_loss(\n",
        "                output,\n",
        "                target.view(-1),\n",
        "                reduction='sum',\n",
        "                ignore_index=0,\n",
        "            )\n",
        "            total_size += size\n",
        "\n",
        "    return total_loss / total_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgZyUehsAw6L",
        "outputId": "9fd36716-83d6-4ca8-9d57-be0bade73fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences loaded\n",
            "Sentences loaded\n",
            "Sentences loaded\n",
            "len ditc:  10002\n",
            "Dictionary's length:  10002  words.\n",
            "epoch:  0  | batches:  51 / 657  | learning_rate:  0.001 | ms/batch:  233.3  | loss:  12.46  | perplexity:  257837.74\n",
            "epoch:  0  | batches:  101 / 657  | learning_rate:  0.001 | ms/batch:  205.7  | loss:  6.46  | perplexity:  638.85\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "\n",
        "    save = 'model_test.pt'\n",
        "    torch.manual_seed(1111)\n",
        "    corpus = Corpus()\n",
        "    print(\"len ditc: \", corpus.len_dict)\n",
        "    model = RNN(corpus.len_dict).to(device)\n",
        "    print(\"Dictionary's length: \", corpus.len_dict, \" words.\")\n",
        "\n",
        "    train_data = corpus.train\n",
        "    test_data = corpus.test\n",
        "    val_data = corpus.valid\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))\n",
        "    # opt = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    best_val_loss = None\n",
        "\n",
        "    try:\n",
        "        for epoch in range(0, epochs):\n",
        "            epoch_start_time = time.time()\n",
        "            train(model, train_data, opt, epoch)\n",
        "            val_loss = evaluate(val_data, model)\n",
        "            ppl = round(math.exp(val_loss),2)\n",
        "\n",
        "            print(\"-----------------------------------------------------------------------------------------\")\n",
        "            print('end epoch: ', epoch, '| time: ', round((time.time() - epoch_start_time),2), 's | valid loss: ', round(val_loss.item(),3),\n",
        "                  '| valid ppl: ', ppl)\n",
        "            print(\"-----------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "            if not best_val_loss or val_loss < best_val_loss:\n",
        "                with open(save, 'wb') as f:\n",
        "                    torch.save(model, f)\n",
        "                best_val_loss = val_loss\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting from training early')\n",
        "\n",
        "    with open(save, 'rb') as f:\n",
        "        model = torch.load(f)\n",
        "\n",
        "    test_loss = evaluate(test_data,model)\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    print('End of training\\ntest loss: ', round(test_loss.item(),3), '\\ntest ppl: ', math.exp(test_loss))\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jVAJ9T-wCqEd"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "223727_NLU_LM2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}